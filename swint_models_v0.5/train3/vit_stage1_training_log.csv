epoch,phase,loss,accuracy
1,train,1.5049847126811189,0.6838111298482293
1,test,0.6895011014762111,0.8184804928131417
2,train,1.4894547870214097,0.6907251264755481
2,test,0.680164159029661,0.8186858316221766
3,train,1.4478255811067295,0.7105677346824059
3,test,0.6777980934912664,0.8209445585215606
4,train,1.4561532327202749,0.7058178752107925
4,test,0.669658692832845,0.8217659137577001
5,train,1.5280032551509735,0.6690275435637999
5,test,0.6947182587774382,0.8205338809034908
6,train,1.4708741270068524,0.7117481731309725
6,test,0.6794388342686992,0.8242299794661191
7,train,1.432579921121474,0.7195053400786959
7,test,0.6688440063895631,0.8238193018480493
8,train,1.4998977902499795,0.7024451939291737
8,test,0.6781976947549432,0.8217659137577001
9,train,1.4613061202919302,0.7096683530073075
9,test,0.6750734740214182,0.8211498973305955
10,train,1.4355923298170488,0.7295952782462057
10,test,0.6716644935539371,0.8205338809034908
11,train,1.460796640387005,0.6940134907251265
11,test,0.6686315509817683,0.8197125256673511
12,train,1.498535062423779,0.6949971894322653
12,test,0.6797258553318909,0.82217659137577
13,train,1.476414804501504,0.7059584035975267
13,test,0.6732029481345378,0.8238193018480493
14,train,1.4428738223896596,0.7144744238336144
14,test,0.6772301752954049,0.8209445585215606
15,train,1.3934242044693301,0.733698707138842
15,test,0.6613615790676532,0.8240246406570841
16,train,1.4161438288817316,0.7209949409780776
16,test,0.662468231581075,0.8246406570841889
17,train,1.4634452771041553,0.6989038785834739
17,test,0.6699495909395159,0.8236139630390144
18,train,1.4262038084145943,0.7251826869027543
18,test,0.6597284220816908,0.8256673511293634
19,train,1.4101473477799413,0.728920741989882
19,test,0.6557713494898113,0.8248459958932238
20,train,1.4611127220157025,0.7243395165823496
20,test,0.6661027317908755,0.8234086242299794
21,train,1.4253907228601723,0.7227093872962338
21,test,0.6548610760935523,0.8268993839835729
22,train,1.3903786778919076,0.7371275997751546
22,test,0.655811558220176,0.8264887063655031
23,train,1.437288854965137,0.7224002248454188
23,test,0.6545885208451038,0.824435318275154
24,train,1.421347831527191,0.7276840921866217
24,test,0.659583402708081,0.8234086242299794
25,train,1.4156046368152388,0.7265317594154019
25,test,0.6517856862755527,0.8256673511293634
26,train,1.4025505919748642,0.7262507026419337
26,test,0.6457205767749027,0.8266940451745379
27,train,1.4360974430300801,0.7305508712759977
27,test,0.6580694083070853,0.8266940451745379
28,train,1.4556674969136012,0.7040191118605958
28,test,0.6565628195690179,0.8293634496919918
29,train,1.4887874309905398,0.7078133783024171
29,test,0.6690916161517588,0.8242299794661191
30,train,1.451762159879855,0.7117481731309725
30,test,0.6573025605761784,0.8250513347022587
31,train,1.445952814666658,0.7143338954468803
31,test,0.6592213800310843,0.8262833675564681
32,train,1.407694482629121,0.7196739741427769
32,test,0.6490060014891184,0.8262833675564681
33,train,1.416771494048978,0.7209949409780776
33,test,0.6495322075467824,0.8264887063655031
34,train,1.3948854645562345,0.7342327150084317
34,test,0.6422716696649117,0.8260780287474333
35,train,1.3741702137400824,0.7305789769533446
35,test,0.6402245918338548,0.8271047227926078
36,train,1.4706785830840292,0.718521641371557
36,test,0.6557252529465443,0.8268993839835729
37,train,1.4663806417271152,0.7032321528948847
37,test,0.6513422363837397,0.8283367556468172
38,train,1.444151752795176,0.711495222034851
38,test,0.6541712808413183,0.8273100616016427
39,train,1.4821880435059083,0.6799606520517144
39,test,0.658383866795769,0.8289527720739219
40,train,1.3808667526947374,0.735637998875773
40,test,0.634829741557276,0.8281314168377824
41,train,1.4237249170547794,0.7267284991568297
41,test,0.6545430207888938,0.8268993839835729
42,train,1.4096558968896207,0.7261382799325464
42,test,0.645665792004039,0.8271047227926078
43,train,1.4340249315549176,0.7168071950534008
43,test,0.653370669735041,0.8277207392197126
