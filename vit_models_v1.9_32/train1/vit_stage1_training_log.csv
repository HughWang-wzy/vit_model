epoch,phase,loss,accuracy
1,train,2.189760223595596,0.22751545812254076
1,test,1.731630971593289,0.3887063655030801
2,train,2.0486054026725387,0.31933670601461495
2,test,1.5859290022624837,0.4305954825462012
3,train,2.016174353824163,0.34468802698145024
3,test,1.5104100666006977,0.46940451745379874
4,train,1.9685104470362886,0.37419898819561553
4,test,1.4843606068123538,0.4913757700205339
5,train,1.9632199091479776,0.3749016301292861
5,test,1.5128162998927936,0.4731006160164271
6,train,1.9473736169031324,0.38594716132658796
6,test,1.3611420504611131,0.5408624229979466
7,train,1.924504525183023,0.40067453625632377
7,test,1.3747022231256694,0.524435318275154
8,train,1.921062686779715,0.4095559302979202
8,test,1.3836902272285132,0.5375770020533881
9,train,1.9011826685266993,0.42251264755480605
9,test,1.3186996614663753,0.5566735112936345
10,train,1.890793934774372,0.4312254075323215
10,test,1.3416837657012,0.5453798767967146
11,train,1.8698441099222622,0.43648116919617763
11,test,1.2265133892486229,0.5759753593429158
12,train,1.8539671714015058,0.4426925238898258
12,test,1.2201505185152717,0.5960985626283367
13,train,1.8576093386102754,0.4468802698145025
13,test,1.1931038360086554,0.6213552361396304
14,train,1.8532417911167156,0.45120854412591344
14,test,1.2475270706525328,0.5706365503080082
15,train,1.8241109155013764,0.46638560989319844
15,test,1.2053361309627244,0.606570841889117
16,train,1.830142573039809,0.46571107363687464
16,test,1.215301083955432,0.6227926078028747
17,train,1.8167946817903051,0.46888701517706577
17,test,1.139812717986058,0.6254620123203285
18,train,1.7878298372951633,0.48583473861720067
18,test,1.1445804525939347,0.6449691991786447
19,train,1.801071496824658,0.48476672287802136
19,test,1.1350967494369288,0.6303901437371663
20,train,1.8229753557921393,0.47689713322091065
20,test,1.2122825113410087,0.6234086242299794
21,train,1.798966710697472,0.4905283867341203
21,test,1.107106837012195,0.6589322381930185
22,train,1.7659203389308773,0.49898819561551433
22,test,1.101181767314856,0.6566735112936345
23,train,1.7683008342059963,0.5060146149522203
23,test,1.0749127458497973,0.6583162217659138
24,train,1.7614338784354533,0.5124789207419899
24,test,1.0641005372609447,0.6634496919917864
25,train,1.7604913446191592,0.5102023608768972
25,test,1.0757428518066172,0.6663244353182751
26,train,1.754236184498646,0.5160764474423833
26,test,1.06009718133194,0.6796714579055442
27,train,1.7479286548460113,0.5186340640809444
27,test,1.087198042967481,0.6630390143737166
28,train,1.7416852777764127,0.5234120292299045
28,test,1.0349618517153072,0.6753593429158111
29,train,1.715051431934642,0.5353569421023047
29,test,1.0269250897411448,0.684599589322382
30,train,1.7105256820140493,0.5398257448004496
30,test,0.9688972631763874,0.6880903490759753
31,train,1.7369234984747943,0.5279370432827432
31,test,0.9898359060287476,0.6864476386036961
32,train,1.7192451450783193,0.534991568296796
32,test,0.9688465898041853,0.6952772073921971
33,train,1.697108862211089,0.5519955030916245
33,test,0.9909225035252267,0.6987679671457906
34,train,1.6905149534487067,0.5502248454187746
34,test,1.0015579754322217,0.6946611909650924
35,train,1.727540075397009,0.5325182686902754
35,test,0.9494466399510049,0.7129363449691992
36,train,1.718635563236599,0.5484541877459247
36,test,0.9741713743679822,0.7106776180698152
37,train,1.719448530023992,0.5384485666104554
37,test,0.9429144216513976,0.7137577002053388
38,train,1.6776335192369973,0.5686059584035975
38,test,0.9531044516720076,0.7053388090349075
39,train,1.6904384442029743,0.5603147835862844
39,test,0.9775484285560232,0.7086242299794661
40,train,1.6982378114134224,0.5582068577852727
40,test,0.940641331550277,0.7209445585215606
41,train,1.660451683185957,0.5717818999437887
41,test,0.9336597441647821,0.7137577002053388
